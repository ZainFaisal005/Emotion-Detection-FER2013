{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiGyzhP6Z8gz"
      },
      "source": [
        "# **Emotion Detection - FER2013**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Downloading Data from Kagglehub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKXIxs6UZ8g1",
        "outputId": "7da4424d-5d20-4e4e-c634-ddedaaac5205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.10).\n",
            "Path to dataset files: C:\\Users\\Zain Faisal\\.cache\\kagglehub\\datasets\\msambare\\fer2013\\versions\\1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Importing Necessary Libararies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JU2v8pCkZ8g3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0, MobileNetV2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Data Paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH367rl8Z8g3"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "data_dir = r\"C:\\Users\\Zain Faisal\\.cache\\kagglehub\\datasets\\msambare\\fer2013\\versions\\1\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "test_dir = os.path.join(data_dir, \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E729WJSPZ8g3"
      },
      "outputs": [],
      "source": [
        "# Image Data Generator with Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=15,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Loading Training and Testing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8jCIB7yZ8g3",
        "outputId": "fcee834a-e950-4397-f283-db724d420088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=64,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=\"categorical\")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=64,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=\"categorical\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxp00CUzZ8g4",
        "outputId": "68f2596e-819e-4253-dc3b-5b8973129d4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Deep CNN Model\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(64, (3,3), activation='relu', input_shape=(48, 48, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(256, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(7, activation='softmax')  # 7 emotion classes\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Using Pretrained Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdNUc6ZjZ8g4",
        "outputId": "e4852ff7-33e1-4a2c-c058-226b868ee071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Pre-trained Model (EfficientNetB0)\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(7, activation='softmax')(x)\n",
        "\n",
        "efficient_model = Model(inputs=base_model.input, outputs=output_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Compilation of Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RF_ux0a2Z8g4"
      },
      "outputs": [],
      "source": [
        "# Compile Models\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "efficient_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Model Checkpoints**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qBdcyGC8Z8g4"
      },
      "outputs": [],
      "source": [
        "# Model Checkpoints\n",
        "checkpoint_cnn = ModelCheckpoint(\"best_cnn_model.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "checkpoint_efficient = ModelCheckpoint(\"best_efficient_model.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ7jc7LKZ8g4",
        "outputId": "4da77e37-d824-4065-aafb-247fa043ff83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.6166 - loss: 1.0272 - val_accuracy: 0.5903 - val_loss: 1.1403\n",
            "Epoch 2/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 64ms/step - accuracy: 0.6248 - loss: 1.0089 - val_accuracy: 0.5770 - val_loss: 1.1437\n",
            "Epoch 3/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6273 - loss: 1.0011"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 65ms/step - accuracy: 0.6273 - loss: 1.0012 - val_accuracy: 0.6113 - val_loss: 1.0451\n",
            "Epoch 4/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - accuracy: 0.6261 - loss: 0.9942 - val_accuracy: 0.6009 - val_loss: 1.0734\n",
            "Epoch 5/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 65ms/step - accuracy: 0.6276 - loss: 0.9923 - val_accuracy: 0.5685 - val_loss: 1.1639\n",
            "Epoch 6/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 62ms/step - accuracy: 0.6353 - loss: 0.9865 - val_accuracy: 0.6053 - val_loss: 1.0753\n",
            "Epoch 7/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - accuracy: 0.6415 - loss: 0.9581 - val_accuracy: 0.6080 - val_loss: 1.0798\n",
            "Epoch 8/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 65ms/step - accuracy: 0.6418 - loss: 0.9632 - val_accuracy: 0.5818 - val_loss: 1.1511\n",
            "Epoch 1/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - accuracy: 0.2497 - loss: 1.8095 - val_accuracy: 0.2471 - val_loss: 1.8132\n",
            "Epoch 2/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 63ms/step - accuracy: 0.2491 - loss: 1.8123 - val_accuracy: 0.2471 - val_loss: 1.8132\n",
            "Epoch 3/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - accuracy: 0.2466 - loss: 1.8125 - val_accuracy: 0.2471 - val_loss: 1.8132\n",
            "Epoch 4/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 63ms/step - accuracy: 0.2485 - loss: 1.8129 - val_accuracy: 0.2471 - val_loss: 1.8132\n",
            "Epoch 5/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 65ms/step - accuracy: 0.2497 - loss: 1.8112 - val_accuracy: 0.2471 - val_loss: 1.8132\n",
            "Epoch 6/20\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 66ms/step - accuracy: 0.2485 - loss: 1.8109 - val_accuracy: 0.2471 - val_loss: 1.8132\n"
          ]
        }
      ],
      "source": [
        "# Train Models\n",
        "history_cnn = cnn_model.fit(train_generator, validation_data=test_generator, epochs=20, callbacks=[checkpoint_cnn, early_stopping])\n",
        "history_efficient = efficient_model.fit(train_generator, validation_data=test_generator, epochs=20, callbacks=[checkpoint_efficient, early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Evaluation of Model and selecting best one**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSBZybRHZ8g5",
        "outputId": "d58fb700-37c3-4bf4-c876-b5675d00e31c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deep CNN model selected as best.\n"
          ]
        }
      ],
      "source": [
        "# Evaluate and Select Best Model\n",
        "cnn_val_acc = max(history_cnn.history['val_accuracy'])\n",
        "efficient_val_acc = max(history_efficient.history['val_accuracy'])\n",
        "\n",
        "if efficient_val_acc > cnn_val_acc:\n",
        "    best_model = efficient_model\n",
        "    best_model.save(\"best_model.h5\")\n",
        "    print(\"EfficientNetB0 model selected as best.\")\n",
        "else:\n",
        "    best_model = cnn_model\n",
        "    best_model.save(\"best_model.h5\")\n",
        "    print(\"Deep CNN model selected as best.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Real Time Detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gjjsPbExZ8g5"
      },
      "outputs": [],
      "source": [
        "# Real-time Emotion Detection via Webcam\n",
        "def real_time_emotion_detection():\n",
        "    model = tf.keras.models.load_model(\"best_model.h5\")\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            face = gray[y:y+h, x:x+w]\n",
        "            face = cv2.resize(face, (48, 48)) / 255.0\n",
        "            face = np.expand_dims(face, axis=0)\n",
        "            face = np.expand_dims(face, axis=-1)\n",
        "\n",
        "            prediction = model.predict(face)\n",
        "            emotion = list(train_generator.class_indices.keys())[np.argmax(prediction)]\n",
        "\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "            cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "        cv2.imshow('Emotion Detection', frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Run Emotion Detection (Uncomment to test in real-time)\n",
        "# real_time_emotion_detection()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
